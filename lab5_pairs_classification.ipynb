{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42e0a71-5efe-40c7-a8de-c5fb1389bdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install transformers[torch] datasets scikit-learn elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7873db1b-7b6a-4c1a-8b6e-fb334685dc94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bac6e264-12f2-4543-80bf-67420f57df5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds_qa = load_dataset(\"clarin-knext/fiqa-pl-qrels\")\n",
    "ds_corpus = load_dataset(\"clarin-knext/fiqa-pl\", \"corpus\")\n",
    "ds_queries = load_dataset(\"clarin-knext/fiqa-pl\", \"queries\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f13dd6c3-582e-453d-8aa2-4b33106fd31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ['3', '31', '56'],\n",
       " 'title': ['', '', ''],\n",
       " 'text': ['Nie mówię, że nie podoba mi się też pomysł szkolenia w miejscu pracy, ale nie możesz oczekiwać, że firma to zrobi. Szkolenie pracowników to nie ich praca – oni tworzą oprogramowanie. Być może systemy edukacyjne w Stanach Zjednoczonych (lub ich studenci) powinny trochę martwić się o zdobycie umiejętności rynkowych w zamian za ich ogromne inwestycje w edukację, zamiast wychodzić z tysiącami zadłużonych studentów i narzekać, że nie są do niczego wykwalifikowani.',\n",
       "  'Tak więc nic nie zapobiega fałszywym ocenom poza dodatkową kontrolą ze strony rynku/inwestorów, ale istnieją pewne nowsze kontrole, które uniemożliwiają instytucjom korzystanie z nich. W ramach DFA banki nie mogą już polegać wyłącznie na ratingach kredytowych jako należytej staranności przy zakupie instrumentu finansowego, więc to jest plus. Intencją jest to, że jeśli instytucje finansowe wykonują swoją własną pracę, to *być może* dojdą do wniosku, że określony CDO jest śmieciem, czy nie. Edycja: wprowadzenie',\n",
       "  'Nigdy nie możesz korzystać z FSA dla indywidualnych składek na ubezpieczenie zdrowotne. Co więcej, sponsorzy planu FSA mogą ograniczyć to, co chcą zwrócić. Chociaż nie możesz użyć FSA zdrowia do składek, wcześniej można było użyć planu kafeteryjnego 125 do opłacania składek, ale musiały to być oddzielne wybory od FSA zdrowia. Jednak zgodnie z N. 2013-54 nawet korzystanie z planu kafeteryjnego do opłacania indywidualnych składek jest skutecznie zabronione.']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ds_corpus['corpus'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba1de375-f089-4fd2-8054-959ec1c6e724",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>Nie mówię, że nie podoba mi się też pomysł szk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31</td>\n",
       "      <td></td>\n",
       "      <td>Tak więc nic nie zapobiega fałszywym ocenom po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>56</td>\n",
       "      <td></td>\n",
       "      <td>Nigdy nie możesz korzystać z FSA dla indywidua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td></td>\n",
       "      <td>Samsung stworzył LCD i inne technologie płaski...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td></td>\n",
       "      <td>Oto wymagania SEC: Federalne przepisy dotycząc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id title                                               text\n",
       "0   3        Nie mówię, że nie podoba mi się też pomysł szk...\n",
       "1  31        Tak więc nic nie zapobiega fałszywym ocenom po...\n",
       "2  56        Nigdy nie możesz korzystać z FSA dla indywidua...\n",
       "3  59        Samsung stworzył LCD i inne technologie płaski...\n",
       "4  63        Oto wymagania SEC: Federalne przepisy dotycząc..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_df = pd.DataFrame(ds_corpus['corpus'])\n",
    "corpus_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3549bf65-c92e-41ce-b20c-0ea62ae2e7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ['0', '4', '5'],\n",
       " 'title': ['', '', ''],\n",
       " 'text': ['Co jest uważane za wydatek służbowy w podróży służbowej?',\n",
       "  'Wydatki służbowe - ubezpieczenie samochodu podlegające odliczeniu za wypadek, który wydarzył się podczas podróży służbowej',\n",
       "  'Rozpoczęcie nowego biznesu online']}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_queries['queries'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fcf480d-7b95-44ce-bbf1-a9d07d67f889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>Co jest uważane za wydatek służbowy w podróży ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Wydatki służbowe - ubezpieczenie samochodu pod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Rozpoczęcie nowego biznesu online</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>„Dzień roboczy” i „termin płatności” rachunków</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>Nowy właściciel firmy – Jak działają podatki d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  _id title                                               text\n",
       "0   0        Co jest uważane za wydatek służbowy w podróży ...\n",
       "1   4        Wydatki służbowe - ubezpieczenie samochodu pod...\n",
       "2   5                        Rozpoczęcie nowego biznesu online\n",
       "3   6           „Dzień roboczy” i „termin płatności” rachunków\n",
       "4   7        Nowy właściciel firmy – Jak działają podatki d..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_df = pd.DataFrame(ds_queries['queries'])\n",
    "queries_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1f2f5b6-3e38-461e-8d3c-229a1dc3fcc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query-id': [0, 4, 5, 6, 6, 6, 7, 9, 9, 11],\n",
       " 'corpus-id': [18850,\n",
       "  196463,\n",
       "  69306,\n",
       "  560251,\n",
       "  188530,\n",
       "  564488,\n",
       "  411063,\n",
       "  509122,\n",
       "  184698,\n",
       "  596427],\n",
       " 'score': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_qa['train'][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d51613-1dc2-4813-b243-5650c7d4a09a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_ids_set = set(ds_qa['train']['query-id'])\n",
    "len(query_ids_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "663f0f0e-cc61-4ba5-8d1f-963488da3339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qa_df = pd.DataFrame(ds_qa['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69ac042e-0c15-4d36-85d8-447461421a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[560251, 188530, 564488]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "188530"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_id = 6\n",
    "qa_related = list(qa_df.loc[qa_df['query-id'] == q_id]['corpus-id'])\n",
    "print(qa_related)\n",
    "random.choice(qa_related)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35a2bd93-24a3-4dc0-a097-8913acfae14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_related_sentences(query_ids, sep_token='|'):\n",
    "    results = []\n",
    "    for q_id in query_ids:\n",
    "        qa_related = list(qa_df[qa_df['query-id'] == q_id]['corpus-id'])\n",
    "        rel_id = random.choice(qa_related)\n",
    "        q_text = queries_df[queries_df['_id'] == str(q_id)]['text'].iloc[0]\n",
    "        rel_text = corpus_df[corpus_df['_id'] == str(rel_id)]['text'].iloc[0]\n",
    "        results.append(q_text + sep_token + rel_text)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85e7875f-57d4-4805-8459-ba9f8091290d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Co jest uważane za wydatek służbowy w podróży służbowej?|Wytyczne IRS dotyczące tematu. Ogólnie rzecz biorąc, najlepsze, co mogę powiedzieć, to to, że Twój wydatek biznesowy może podlegać odliczeniu. Ale to zależy od okoliczności i tego, co chcesz odliczyć. Podróże Podatnicy, którzy wyjeżdżają z domu w celach służbowych, mogą odliczyć związane z tym wydatki, w tym koszty dotarcia do miejsca docelowego, koszty zakwaterowania i wyżywienia oraz inne zwykłe i niezbędne wydatki. Podatnicy są uważani za „wyjeżdżających poza dom”, jeśli ich obowiązki wymagają od nich przebywania poza domem znacznie dłużej niż zwykły dzień pracy i muszą spać lub odpoczywać, aby sprostać wymogom pracy. Można odliczyć rzeczywisty koszt posiłków i nieprzewidziane wydatki lub skorzystać ze standardowej diety żywieniowej i obniżonych wymogów ewidencji. Niezależnie od zastosowanej metody odliczenia posiłków są zazwyczaj ograniczone do 50 procent, jak wspomniano wcześniej. Jako koszt można zgłaszać tylko rzeczywiste koszty zakwaterowania, a rachunki należy przechowywać do dokumentacji. Wydatki muszą być rozsądne i odpowiednie; potrącenia z tytułu nadmiernych wydatków nie są dopuszczalne. Więcej informacji można znaleźć w publikacji 463, Podróże, rozrywka, prezenty i wydatki na samochód. Rozrywka Wydatki na rozrywkę dla klientów, klientów lub pracowników mogą być odliczane, jeśli są one zarówno zwyczajne, jak i konieczne oraz spełniają jeden z następujących testów: Test bezpośrednio związany: Głównym celem działalności rozrywkowej jest prowadzenie działalności, działalność była faktycznie prowadzona podczas działalność i podatnik mieli więcej niż ogólne oczekiwanie uzyskania dochodu lub innej konkretnej korzyści biznesowej w przyszłości. Powiązany test: rozrywka była związana z aktywnym prowadzeniem działalności handlowej lub biznesowej podatnika i miała miejsce bezpośrednio przed lub po istotnej dyskusji biznesowej. Publikacja 463 zawiera obszerniejsze wyjaśnienie tych testów, jak również innych ograniczeń i wymagań dotyczących odliczania wydatków na rozrywkę. Prezenty Podatnicy mogą odliczyć część lub całość kosztów prezentów wręczanych w ramach ich działalności handlowej lub biznesowej. Ogólnie rzecz biorąc, odliczenie jest ograniczone do 25 USD za prezenty wręczane bezpośrednio lub pośrednio jednej osobie w ciągu roku podatkowego. Więcej omówienia zasad i ograniczeń można znaleźć w Publikacji 463. Jeśli Twoja spółka LLC zwróci Ci wydatki wykraczające poza te wytyczne, należy je traktować jako dochód dla celów podatkowych. Edytuj koszty posiłków: Kwota standardowego dodatku na posiłki. Standardowy dodatek na posiłki to federalna stawka M&IE. W przypadku podróży w 2010 r. stawka dla większości małych miejscowości w Stanach Zjednoczonych wynosi 46 USD dziennie. Źródło IRS P463 Alternatywnie możesz dokonać zwrotu według stawki dziennej',\n",
       " 'Wydatki służbowe - ubezpieczenie samochodu podlegające odliczeniu za wypadek, który wydarzył się podczas podróży służbowej|Co do zasady musisz wybrać pomiędzy odliczeniem kilometrów a rzeczywistym odliczeniem kosztów. Chodzi o to, aby odliczenie kilometrów miało pokryć wszystkie koszty użytkowania auta. Wyjątkiem są opłaty parkingowe i opłaty drogowe, które można odliczyć osobno w obu przypadkach. Wyraźnie nie możesz odliczyć kosztów ubezpieczenia, jeśli ubiegasz się o odliczenie kilometrażu. Osobno prawdopodobnie nie będziesz w stanie odliczyć udziału własnego za swój samochód jako stratę w wyniku wypadku. Najpierw odejmujesz 100 USD od odliczenia, a następnie dzielisz je przez skorygowany dochód brutto (AGI) z zeznania podatkowego. Jeśli twój udział własny przekracza 10% twojego AGI, możesz go odliczyć. Pamiętaj, że nawet z odliczeniem w wysokości 1500 USD nie będziesz w stanie niczego odliczyć, jeśli zarobisz więcej niż 14 000 USD w ciągu roku. Dla większości ludzi odliczenie od ubezpieczenia po prostu nie jest wystarczająco duże w stosunku do dochodu, aby można je było odliczyć od podatku. Źródło',\n",
       " 'Rozpoczęcie nowego biznesu online|Większość stanów USA ma zasady, które brzmią mniej więcej tak: prawie na pewno będziesz musiał uiścić pewne opłaty rejestracyjne, jak wspomniano powyżej. W zależności od sposobu organizacji może być konieczne złożenie oddzielnego zeznania podatkowego dla firmy lub nie. (Jeżeli jesteś jednoosobowym właścicielem dla celów podatkowych, składasz wniosek zgodnie z Załącznikiem C na swoim osobistym formularzu 1040.) To, czy płacisz podatki, zależy od tego, czy masz dochód netto. Możliwe, że część strat również podlega odliczeniu. (Pamiętaj, że może być konieczne złożenie zeznania, nawet jeśli nie masz dochodu netto – składanie i konieczność zapłaty to nie to samo, ponieważ zeznanie może wskazywać na brak należnego podatku.) Ponadto na poziomie stanowym możesz mieć aby zapłacić dodatkowe opłaty lub podatki poza podatkiem dochodowym w zależności od tego, co sprzedajesz i jak to sprzedajesz. (Na przykład podatek od sprzedaży może wejść w grę, podobnie jak podatki od franczyzy). Jak zawsze, rozsądnie byłoby uzyskać profesjonalne porady podatkowe i księgowe, które są dostosowane do Twojej sytuacji i stanu. To tylko zarys kilku rzeczy, które należy wziąć pod uwagę.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_related_sentences([0, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5362a833-41c9-4696-9bd9-65d694a38f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[SEP]'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"dkleczek/bert-base-polish-cased-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "polbert_separator = tokenizer.sep_token\n",
    "polbert_separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "669a729f-5ce7-491d-8e77-8608e0067c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Kiedy powinienem zacząć oszczędzać/inwestować na emeryturę?[SEP]Zacznij jak najszybciej i zrób swoją rutynę oszczędzania. Zacznij od tego, z czym czujesz się komfortowo i bądź konsekwentny. Zwiększ tę kwotę za pomocą podwyżek, zysków i kiedy tylko chcesz.',\n",
       " 'W jaki sposób obywatel spoza USA uzyskuje status akredytowanego inwestora SEC?[SEP]Oto wymagania SEC: Federalne przepisy dotyczące papierów wartościowych definiują termin inwestora akredytowanego w zasadzie 501 Regulacji D jako: bank, firma ubezpieczeniowa, zarejestrowana firma inwestycyjna, firma zajmująca się rozwojem działalności lub firma inwestycyjna dla małych firm; program świadczeń pracowniczych w rozumieniu ustawy o zabezpieczeniach emerytalnych pracowników, jeżeli decyzje inwestycyjne podejmuje bank, towarzystwo ubezpieczeniowe lub zarejestrowany doradca inwestycyjny lub jeżeli suma aktywów programu przekracza 5 mln USD; organizacja charytatywna, korporacja lub spółka partnerska z majątkiem przekraczającym 5 milionów USD; dyrektor, dyrektor wykonawczy lub komplementariusz firmy sprzedającej papiery wartościowe; przedsiębiorstwo, w którym wszyscy właściciele akcji są akredytowanymi inwestorami; osoba fizyczna, która posiada indywidualną wartość netto lub wspólną wartość netto z małżonkiem tej osoby, która w momencie zakupu przekracza 1 milion USD, z wyłączeniem wartości głównego miejsca zamieszkania takiej osoby; osoba fizyczna z dochodem przekraczającym 200 000 USD w każdym z dwóch ostatnich lat lub łączny dochód z małżonkiem przekraczający 300 000 USD w tych latach i uzasadnione oczekiwanie takiego samego poziomu dochodów w bieżącym roku; lub fundusz powierniczy z aktywami przekraczającymi 5 milionów USD, niezałożony w celu nabycia oferowanych papierów wartościowych, którego zakupów dokonuje wyrafinowana osoba. Brak wymagań dotyczących obywatelstwa/miejsca zamieszkania.',\n",
       " 'Kanadyjczyk przyjmujący pieniądze drogą elektroniczną od Amerykanów[SEP]Nie znam wersji Interac dostępnej w USA, ale istnieją alternatywne sposoby otrzymania pieniędzy: czek. Problem z czekami wysyłanymi pocztą polega na tym, że ich dostarczenie i rozliczenie zajmuje trochę czasu. Jeśli wyślesz swoje towary, zanim czek zostanie zrealizowany, a czek będzie zły, stracisz towar. DORSZ. Działa to w taki sposób, że na poczcie naliczasz opłatę za pobraniem w wysokości, którą obciążasz klienta. Poczta dostarcza paczkę na drugi koniec, gdy klient płaci. Poczta płaci Ci w momencie wysłania paczki. Jest za to opłata, porozmawiaj z lokalnym urzędem pocztowym lub odwiedź witrynę Canada Post. Przekaz pieniężny. Poproś klientów z USA o przesłanie międzynarodowego przekazu pieniężnego, a nie krajowego przekazu pieniężnego. Krajowe przekazy pieniężne można zrealizować tylko w urzędzie pocztowym USA. Problemem jest tutaj ponownie czas dostawy i weryfikacja, czy klient wysłał międzynarodowy przekaz pieniężny. Odesłanie krajowego przekazu pieniężnego do klienta z wyjaśnieniem, co musi zrobić, aby Ci zapłacić, może być uciążliwe, a jeszcze bardziej bolesne, jeśli nie wykryjesz błędu przed wysyłką towarów. Karta kredytowa. Istnieje wiele firm oferujących przetwarzanie kart kredytowych, które są znacznie tańsze niż bank. PayPal, Square i Intuit to trzy takie firmy oferujące te usługi. Po przeprowadzeniu dochodzenia stwierdziłem, że Square jest dla mnie najlepszą ofertą. Przeprowadź własne badania na temat tych firm (i banków!) i dowiedz się, która z nich jest dla Ciebie najbardziej sensowna. Niektóre firmy transakcyjne mogą zabronić przetwarzania płatności za materiały do \\u200b\\u200be-papierosów, ponieważ są one klasyfikowane jako tytoń.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 2500\n",
    "related_sentences = prepare_related_sentences(random.sample(list(query_ids_set), N), polbert_separator)\n",
    "related_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "af1e843b-4515-438e-b0d0-73baece71bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved/related.txt', 'w') as f:\n",
    "    for line in related_sentences:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c4e727f5-d0ad-4349-ae2a-6cf0231d1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_unrelated_sentences(query_ids, sep_token='|'):\n",
    "    results = []\n",
    "    for q_id in query_ids:\n",
    "        qa_related = list(qa_df[qa_df['query-id'] == q_id]['corpus-id'])\n",
    "        random_corp_id = random.choice(ds_qa['train']['corpus-id'])\n",
    "        while random_corp_id in qa_related: # to assure that related text with be taken\n",
    "            random_corp_id = random.choice(ds_qa['train']['corpus-id'])\n",
    "\n",
    "        q_text = queries_df[queries_df['_id'] == str(q_id)]['text'].iloc[0]\n",
    "        unrel_text = corpus_df[corpus_df['_id'] == str(random_corp_id)]['text'].iloc[0]\n",
    "        results.append(q_text + sep_token + unrel_text)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f6a45c1-e93f-4d9b-8c65-722e04dc6a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spółka chce sprzedać wszystkie swoje aktywa, warte więcej niż cena akcji?[SEP]Moje doświadczenie (z krajów europejskich, ale nie konkretnie Portugalii) jest takie, że lepiej zmienić się w kraju europejskim, ponieważ wiele banków oczywiście da ci dolary amerykańskie, podczas gdy w USA (jest to wyspiarskie miejsce) może być dość trudno znaleźć miejsce do wymiany pieniędzy poza międzynarodowym lotniskiem. Właściwie zostało mi kilkaset euro z ostatniej podróży sprzed kilku lat. Spodziewałem się, że odbędą kolejną podróż, która się nie udała i nie znalazłem miejsca, aby je wymienić. PS: Gwoli informacji, w czasie, gdy pracowałem w Europie i stwierdziłem, że zdecydowanie najłatwiejszym sposobem na przeniesienie części mojej pensji do domu jest otrzymanie 100-dolarowych banknotów z mojego europejskiego banku. Innym sposobem było wypłata pieniędzy z bankomatu, ponieważ banki amerykańskie i europejskie były w tej samej sieci. Niestety IRS położył temu kres, chociaż nie wiem, czy to były wszystkie banki, czy tylko ten, z którego korzystałem. Może jednak warto to sprawdzić.',\n",
       " 'Raport kredytowy – Nie można ustalić tożsamości[SEP]Wzrost o 401 tys. pozwala uniknąć podatków, co oznacza, że \\u200b\\u200bwięcej zysków jest reinwestowanych. W rzeczywistości jest to zwiększona stopa zwrotu. Jak każda inwestycja, 401k może stracić na wartości. W okresie przed przejściem na emeryturę niższe ceny akcji i obligacji faktycznie pomagają kupić więcej akcji, niż byłoby to możliwe, gdyby ceny były wysokie, więc prawdziwe pytanie brzmi, co robią fundusze w momencie, gdy zaczynasz wycofywać pieniądze. Ta obawa powoduje, że generalnie inwestorzy, a nie tylko 401 tys. A jeśli Twój pracodawca dopasuje w jakimkolwiek stopniu składki 401 tys. Stąd ogólna rada, że \\u200b\\u200bjeśli nie sfinansujesz swojego 401k przynajmniej na tyle, aby zmaksymalizować mecz firmy, zostawiasz darmowe pieniądze na stole.',\n",
       " 'Przedpłata pożyczki: Czy odsetki nie powinny być przeliczane jak krótsza pożyczka?[SEP]Z wyjątkiem nietypowych sytuacji podatkowych Twoja efektywna stopa procentowa po uwzględnieniu odliczenia podatkowego będzie nadal dodatnia. Jest po prostu pomniejszony o twoją krańcową stawkę. Dlatego zapłacisz więcej, jeśli dom będzie finansowany, niż jeśli zostanie kupiony od razu. Należy pamiętać, że nie uwzględnia to innych czynników, takich jak utrzymanie płynności lub możliwości uzyskania większej stopy zwrotu poprzez inwestowanie pieniędzy, które w przeciwnym razie zostałyby wykorzystane na opłacenie domu']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N2 = 5000 # ratio of 'positive' to 'negative' will be 1:2\n",
    "unrelated_sentences = prepare_unrelated_sentences(random.sample(list(query_ids_set), N2), polbert_separator)\n",
    "unrelated_sentences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d67188de-4709-4897-a7cc-1c97bed0e5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('saved/unrelated.txt', 'w') as f:\n",
    "    for line in unrelated_sentences:\n",
    "        f.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0146f3c1-efc1-4d3d-9c97-49ca8ca45941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dkleczek/bert-base-polish-cased-v1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(60000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ad2e5156-147b-412b-93bb-6e2290637c02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kiedy powinienem zacząć oszczędzać/inwestować ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W jaki sposób obywatel spoza USA uzyskuje stat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanadyjczyk przyjmujący pieniądze drogą elektr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jaka jest najlepsza inwestycja, która jest w p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czy są jakieś statystyki potwierdzające potrze...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Kiedy powinienem zacząć oszczędzać/inwestować ...      1\n",
       "1  W jaki sposób obywatel spoza USA uzyskuje stat...      1\n",
       "2  Kanadyjczyk przyjmujący pieniądze drogą elektr...      1\n",
       "3  Jaka jest najlepsza inwestycja, która jest w p...      1\n",
       "4  Czy są jakieś statystyki potwierdzające potrze...      1"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related_sentences_df = pd.DataFrame({\n",
    "                        \"text\": related_sentences,\n",
    "                        \"label\": [1 for _ in range(len(related_sentences))],\n",
    "                    })\n",
    "\n",
    "related_sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e2b68fc5-38e5-489d-962b-37f18c48d8a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Spółka chce sprzedać wszystkie swoje aktywa, w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raport kredytowy – Nie można ustalić tożsamośc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Przedpłata pożyczki: Czy odsetki nie powinny b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kiedy zostaną wydane formularze podatku federa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zapytania o akcje[SEP]„Dodam jeszcze jedną poz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Spółka chce sprzedać wszystkie swoje aktywa, w...      0\n",
       "1  Raport kredytowy – Nie można ustalić tożsamośc...      0\n",
       "2  Przedpłata pożyczki: Czy odsetki nie powinny b...      0\n",
       "3  Kiedy zostaną wydane formularze podatku federa...      0\n",
       "4  Zapytania o akcje[SEP]„Dodam jeszcze jedną poz...      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unrelated_sentences_df = pd.DataFrame({\n",
    "                        \"text\": unrelated_sentences,\n",
    "                        \"label\": [0 for _ in range(len(unrelated_sentences))],\n",
    "                    })\n",
    "\n",
    "unrelated_sentences_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c25539b9-9758-4c50-b7ac-898242958435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kiedy powinienem zacząć oszczędzać/inwestować ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>W jaki sposób obywatel spoza USA uzyskuje stat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kanadyjczyk przyjmujący pieniądze drogą elektr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jaka jest najlepsza inwestycja, która jest w p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czy są jakieś statystyki potwierdzające potrze...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7495</th>\n",
       "      <td>Pożyczka osobista dla przyjaciela procedura[SE...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7496</th>\n",
       "      <td>Czy podatek obrotowy od zakupów online jest op...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7497</th>\n",
       "      <td>Dochodzenie dochodów/odliczeń z nielegalnego m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7498</th>\n",
       "      <td>Dlaczego karty American Express nie są tak pop...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7499</th>\n",
       "      <td>Międzynarodowe (ex-US) ETF z niską ekspozycją ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "0     Kiedy powinienem zacząć oszczędzać/inwestować ...      1\n",
       "1     W jaki sposób obywatel spoza USA uzyskuje stat...      1\n",
       "2     Kanadyjczyk przyjmujący pieniądze drogą elektr...      1\n",
       "3     Jaka jest najlepsza inwestycja, która jest w p...      1\n",
       "4     Czy są jakieś statystyki potwierdzające potrze...      1\n",
       "...                                                 ...    ...\n",
       "7495  Pożyczka osobista dla przyjaciela procedura[SE...      0\n",
       "7496  Czy podatek obrotowy od zakupów online jest op...      0\n",
       "7497  Dochodzenie dochodów/odliczeń z nielegalnego m...      0\n",
       "7498  Dlaczego karty American Express nie są tak pop...      0\n",
       "7499  Międzynarodowe (ex-US) ETF z niską ekspozycją ...      0\n",
       "\n",
       "[7500 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.concat([related_sentences_df[:], unrelated_sentences_df[:]], ignore_index=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1e56d1a-d6cf-4717-b8e7-4cb949701b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train:val:test proportion will be 75:15:10\n",
    "train_data, temp_data = train_test_split(dataset, test_size=0.25, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.4, random_state=42)\n",
    "\n",
    "train_data.to_csv(\"saved/train.csv\", index=False)\n",
    "val_data.to_csv(\"saved/val.csv\", index=False)\n",
    "test_data.to_csv(\"saved/test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8a80afb2-85b7-46d9-8095-9fcbeef7e719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 5625 examples [00:00, 70777.89 examples/s]\n",
      "Generating validation split: 1125 examples [00:00, 70440.41 examples/s]\n",
      "Generating test split: 750 examples [00:00, 66593.17 examples/s]\n",
      "Map: 100%|█████████████████████████| 5625/5625 [00:00<00:00, 8914.54 examples/s]\n",
      "Map: 100%|█████████████████████████| 1125/1125 [00:00<00:00, 8694.80 examples/s]\n",
      "Map: 100%|███████████████████████████| 750/750 [00:00<00:00, 8523.99 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "data_files = {\n",
    "    \"train\": \"saved/train.csv\",\n",
    "    \"validation\": \"saved/val.csv\",\n",
    "    \"test\": \"saved/test.csv\"\n",
    "}\n",
    "raw_datasets = load_dataset(\"csv\", data_files=data_files)\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=256) # max_lenght set to 256 which seems to be reasonable\n",
    "\n",
    "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "035e379e-afb8-4901-a952-c0e17677c3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 5625\n",
       "})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "39e5180a-e023-472d-9965-ae1a1227f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example['text'] = 'Czy osoby fizyczne mogą handlować akcjami w trybie dziennym przy użyciu handlu wysokiej częstotliwości (HFT)?[SEP]Coś, co chciałbym mocno zakorzenić w twoim umyśle - Jeśli jesteś w stanie zaoszczędzić wystarczająco dużo pieniędzy, aby kupić rzeczy, których chcesz od razu, kredyt na niewiele ci się przyda. Wiele osób po zgromadzeniu bardzo dobrych wyników kredytowych dzięki dobrym nawykom finansowym stwierdza, że \\u200b\\u200brzadko korzystają z kredytu i niewiele zyskują z posiadania „świetnej” oceny kredytowej w porównaniu z „przeciętną” oceną kredytową. Oczywiście wiele z tego zależałoby od Twojej sytuacji finansowej, ale warto o tym pamiętać. Jak stwierdzili inni i szeroko udokumentowano online, nie musisz dokonywać spłat pożyczki ani nosić salda karty, aby budować swoją historię kredytową. Sprawdź swój kredyt na popularnej stronie, takiej jak Credit Karma (brak przynależności). Tam zobaczysz szczegółowy podział różnych obszarów Twojego profilu kredytowego, które mają znaczenie; rzeczy takie jak: Najlepszą rzeczą, jaką mógłbym polecić, jest uzyskanie linii kredytowej lub karty kredytowej i korzystanie z niej w sposób odpowiedzialny. Posiadanie salda spowoduje marnowanie pieniędzy na odsetki, podobnie jak płatność za samochód. Samo posiadanie go i nie nadużywanie go (lub nieużywanie go w ogóle) „zbuduje” Twoją historię kredytową. Oczywiście niektóre instytucje mogą zamknąć Twoje konto po X latach nieaktywności. Mając to na uwadze, powiedziałbym, że spłata kredytu samochodowego jest bezpieczna. Przeczytaj swoją umowę i upewnij się, że nie ma opłat za wcześniejsze wypowiedzenie/wczesną płatność. Edycja: W sekcji komentarzy z pytaniami/odpowiedziami pojawiły się uwagi dotyczące obaw związanych z uzyskaniem mieszkania. Moje dwa centy tutaj: Większość mieszkań, które widziałem, sprawdza twój kredyt pod kątem negatywnych ocen. Brak historii kredytowej, a co za tym idzie, brak płatności lub orzeczenie przeciwko tobie, prawdopodobnie wystarczy, aby dostać się do większości mieszkań o normalnej jakości, zakładając, że reszta aplikacji / profilu jest w porządku, na przykład: - Dobre referencje , jeśli zostaniesz o to poproszony - Co najmniej 2,5-krotność czynszu w dochodzie brutto itp., takie rzeczy. Jeśli naprawdę uważają, że stwarzasz ryzyko, mogą poprosić o większą kaucję (chociaż jestem pewien, że w niektórych obszarach mogą obowiązywać ograniczenia dotyczące tego, czy mogą to zrobić lub ile mogą to zrobić) i nadal pozwalają ci wynająć tam.'\n",
      "example['input_ids'] = [2, 1168, 2643, 18271, 1646, 43379, 489, 18098, 829, 91, 8206, 38932, 842, 9066, 9195, 6472, 15132, 12, 44, 47573, 13, 35, 4, 3817, 16, 908, 4596, 7250, 46819, 1878, 91, 4230, 32789, 17, 1441, 1285, 91, 2279, 19319, 8212, 2896, 4311, 16, 1326, 6443, 2294, 16, 1741, 2079, 819, 6111, 16, 9204, 752, 11718, 1054, 781, 22002, 18, 7457, 1864, 750, 39096, 1151, 10567, 7723, 33873, 2621, 6446, 58764, 793, 19420, 16443, 16, 810, 12817, 20016, 94, 24414, 77, 11718, 15521, 804, 94, 16457, 368, 14943, 420, 367, 6351, 24244, 91, 8399, 94, 368, 11640, 17794, 367, 38616, 33676, 18, 2851, 1898, 94, 980, 24970, 854, 819, 12987, 3319, 13182, 16, 1005, 6812, 83, 937, 9261, 18, 1099, 45405, 6588, 77, 10430, 23851, 1966, 2040, 16, 772, 3020, 29185, 16028, 415, 29831, 2399, 16305, 5880, 841, 7245, 16, 1326, 18571, 2530, 7492, 33676, 18, 7407, 2819, 9204, 752, 38506, 2686, 16, 4377, 848, 13304, 2491, 415, 43773, 12, 4156, 33462, 13, 18, 3847, 14128, 36936, 10145, 3081, 10573, 9037, 16287, 23944, 761, 16, 996, 1812, 5949, 31, 2294, 1566, 848, 30, 6173, 1332, 11241, 16, 3766, 9992, 57999, 489, 16, 800, 16313, 3773, 24244, 1001, 7245, 24244, 77, 13432, 94, 2486, 91, 1626, 10475, 18, 48644, 5880, 841, 14826, 43707, 1029, 4311, 752, 52843, 16, 6696, 848, 40733, 778, 4823, 18, 7515, 16937, 990, 77, 772, 17445, 1834, 990, 12, 1001, 17442, 1834, 990, 91, 4170, 13, 368, 4083, 1172, 367, 19710, 7492, 33676, 18, 2851, 6261, 12186, 1646, 13242, 4046, 6530, 750, 60, 4]\n",
      "example['attention_mask'] = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "example = tokenized_datasets[\"train\"][0]\n",
    "print(f\"{example['text'] = }\")\n",
    "print(f\"{example['input_ids'] = }\")\n",
    "print(f\"{example['attention_mask'] = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4af21ce9-6c46-4f9b-b938-19da359d1afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]|Czy|osoby|fizyczne|mogą|handlowa|##ć|akcja|##mi|w|trybie|dziennym|przy|użyciu|handlu|wysokiej|częstotliwości|(|H|##FT|)|?|[SEP]|Coś|,|co|chciałbym|mocno|zakorze|##nić|w|twoim|umyśle|-|Jeśli|jesteś|w|stanie|zaoszczędzić|wystarczająco|dużo|pieniędzy|,|aby|kupić|rzeczy|,|których|chcesz|od|razu|,|kredyt|na|niewiele|ci|się|przyda|.|Wiele|osób|po|zgromadzeniu|bardzo|dobrych|wyników|kredytowych|dzięki|dobrym|nawyk|##om|finansowym|stwierdza|,|że|rzadko|korzystają|z|kredytu|i|niewiele|zysku|##ją|z|posiadania|„|świetne|##j|”|oceny|kredytowej|w|porównaniu|z|„|przecię|##tną|”|oceną|kredytową|.|Oczywiście|wiele|z|tego|zależało|##by|od|Twojej|sytuacji|finansowej|,|ale|warto|o|tym|pamiętać|.|Jak|stwierdzili|inni|i|szeroko|udokument|##owano|online|,|nie|musisz|dokonywać|spła|##t|pożyczki|ani|nosić|sal|##da|karty|,|aby|budować|swoją|historię|kredytową|.|Sprawdź|swój|kredyt|na|popularnej|stronie|,|takiej|jak|Cre|##di|##t|Karma|(|brak|przynależności|)|.|Tam|zobaczysz|szczegółowy|podział|różnych|obszarów|Twojego|profilu|kredytowe|##go|,|które|mają|znaczenie|;|rzeczy|takie|jak|:|Najlep|##szą|rzeczą|,|jaką|mógłbym|poleci|##ć|,|jest|uzyskanie|linii|kredytowej|lub|karty|kredytowej|i|korzystanie|z|niej|w|sposób|odpowiedzialny|.|Posiadanie|sal|##da|spowoduje|marn|##owanie|pieniędzy|na|odsetki|,|podobnie|jak|płatność|za|samochód|.|Samo|posiadanie|go|i|nie|naduży|##wanie|go|(|lub|nieuży|##wanie|go|w|ogóle|)|„|zbud|##uje|”|Twoją|historię|kredytową|.|Oczywiście|niektóre|instytucje|mogą|zamknąć|Twoje|konto|po|X|[SEP]\n"
     ]
    }
   ],
   "source": [
    "print(\"|\".join(tokenizer.convert_ids_to_tokens(list(example[\"input_ids\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b9105ca9-a1f4-42f9-aa95-d275521f2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    logging_dir=\"./logs\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# learning_rate, and batch sized choosen based on https://github.com/google-research/bert\n",
    "# num_train_epochs set up to 5 (previously 3) to see if it can improve anything\n",
    "# the rest of the parameters remain default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "63e7905f-05a7-41b8-a287-9f0ef216cf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    predictions = np.argmax(pred.predictions, axis=1)\n",
    "    labels = pred.label_ids\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    auc = roc_auc_score(labels, predictions)\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, predictions, average=\"binary\")\n",
    "    return {\"accuracy\": acc, \"precision\": precision, \"recall\": recall, \"f1\": f1, 'auc': auc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ad3edf4e-7e97-4dbf-8986-f4042b44c181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15174/564752669.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82f81faf-7cd8-4464-a7d3-73aa67c60b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='880' max='880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [880/880 12:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302986</td>\n",
       "      <td>0.879111</td>\n",
       "      <td>0.806295</td>\n",
       "      <td>0.856041</td>\n",
       "      <td>0.830424</td>\n",
       "      <td>0.873673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.330548</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.804706</td>\n",
       "      <td>0.879177</td>\n",
       "      <td>0.840295</td>\n",
       "      <td>0.883203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.347652</td>\n",
       "      <td>0.891556</td>\n",
       "      <td>0.852243</td>\n",
       "      <td>0.830334</td>\n",
       "      <td>0.841146</td>\n",
       "      <td>0.877124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.499339</td>\n",
       "      <td>0.882667</td>\n",
       "      <td>0.876833</td>\n",
       "      <td>0.768638</td>\n",
       "      <td>0.819178</td>\n",
       "      <td>0.855786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.293900</td>\n",
       "      <td>0.528900</td>\n",
       "      <td>0.890667</td>\n",
       "      <td>0.869444</td>\n",
       "      <td>0.804627</td>\n",
       "      <td>0.835781</td>\n",
       "      <td>0.870384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=880, training_loss=0.1968797423622825, metrics={'train_runtime': 738.1487, 'train_samples_per_second': 38.102, 'train_steps_per_second': 1.192, 'total_flos': 3699999216000000.0, 'train_loss': 0.1968797423622825, 'epoch': 5.0})"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "99f0dcbf-5649-4958-89c2-28f2ffdd7a21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='36' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [36/36 00:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: {'eval_loss': 0.3476518392562866, 'eval_accuracy': 0.8915555555555555, 'eval_precision': 0.8522427440633246, 'eval_recall': 0.8303341902313625, 'eval_f1': 0.8411458333333334, 'eval_auc': 0.8771236168548115, 'eval_runtime': 10.3205, 'eval_samples_per_second': 109.006, 'eval_steps_per_second': 3.488, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:79: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.device(device), torch.cuda.stream(stream), autocast(enabled=autocast_enabled):\n",
      "/home/mklimek/venvs/pytorch-env/lib/python3.12/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Metrics: {'eval_loss': 0.3994769752025604, 'eval_accuracy': 0.872, 'eval_precision': 0.8384615384615385, 'eval_recall': 0.8014705882352942, 'eval_f1': 0.8195488721804511, 'eval_auc': 0.8568022397243417, 'eval_runtime': 6.9299, 'eval_samples_per_second': 108.226, 'eval_steps_per_second': 3.463, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "validation_metrics = trainer.evaluate(tokenized_datasets[\"validation\"])\n",
    "print(\"Validation Metrics:\", validation_metrics)\n",
    "\n",
    "test_metrics = trainer.evaluate(tokenized_datasets[\"test\"])\n",
    "print(\"Test Metrics:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "bbf857d4-899a-406b-8193-d567bd4fb4ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_model/tokenizer_config.json',\n",
       " './fine_tuned_model/special_tokens_map.json',\n",
       " './fine_tuned_model/vocab.txt',\n",
       " './fine_tuned_model/added_tokens.json',\n",
       " './fine_tuned_model/tokenizer.json')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.save_model(\"./fine_tuned_model\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f9c4875f-42ec-4b16-bac8-9dc191bebab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"text-classification\", model=\"./fine_tuned_model\", tokenizer=\"./fine_tuned_model\", device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "577884af-984f-44bc-8ea2-5d2445353d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9959685802459717}]\n"
     ]
    }
   ],
   "source": [
    "result = classifier([example['text']])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4d433caa-ab98-4102-add7-5719f43c8df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ES code based on lab 2\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "es = Elasticsearch(\n",
    "    hosts=[\"http://localhost:9200\"],\n",
    "    request_timeout=60\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bc4e6f90-44b5-4daf-9d60-2dbd0e30ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzers_config = {\n",
    "    \"settings\": {\n",
    "        \"analysis\": {\n",
    "            \"analyzer\": {\n",
    "                \"morfologik_analyzer\": {\n",
    "                    \"type\": \"custom\",\n",
    "                    \"tokenizer\": \"standard\",\n",
    "                    \"filter\": [\n",
    "                        \"lowercase\",\n",
    "                        \"morfologik_stem\",\n",
    "                        \"lowercase\"\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bf8fd15e-817c-48f4-bb6e-eac1ee3632d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzers_config[\"mappings\"] = {\"properties\": {\n",
    "                                    \"fiqa_id\": {\n",
    "                                            \"type\": \"keyword\"\n",
    "                                    },\n",
    "                                    \"fiqa_morfologik\": {\n",
    "                                        \"type\": \"text\",\n",
    "                                        \"analyzer\": \"morfologik_analyzer\"\n",
    "                                    }\n",
    "                                }}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b0b03fc-b5f0-42a3-8399-72b3f0692adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index fiqa_index already exists\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'acknowledged': True, 'shards_acknowledged': True, 'index': 'fiqa_index'})"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = 'fiqa_index'\n",
    "\n",
    "if es.indices.exists(index=index_name):\n",
    "    print(f\"index {index_name} already exists\")\n",
    "    es.indices.delete(index=index_name)\n",
    "\n",
    "es.indices.create(index=index_name, body=analyzers_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "af8eb590-4cea-4954-94d9-11f20795cbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'fiqa_index': {'settings': {'index': {'routing': {'allocation': {'include': {'_tier_preference': 'data_content'}}}, 'number_of_shards': '1', 'provided_name': 'fiqa_index', 'creation_date': '1732483046640', 'analysis': {'analyzer': {'morfologik_analyzer': {'filter': ['lowercase', 'morfologik_stem', 'lowercase'], 'type': 'custom', 'tokenizer': 'standard'}}}, 'number_of_replicas': '1', 'uuid': 'InbN0J6xT-2QUspH7shcCQ', 'version': {'created': '8512000'}}}}})"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "settings = es.indices.get_settings(index=index_name)\n",
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "634cad10-ac56-4911-9233-6b8df10a2448",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'fiqa_index': {'mappings': {'properties': {'fiqa_id': {'type': 'keyword'}, 'fiqa_morfologik': {'type': 'text', 'analyzer': 'morfologik_analyzer'}}}}})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings = es.indices.get_mapping(index=index_name)\n",
    "mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec9f3f13-fc59-4e48-a7e5-4e4efaa99a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_to_add = [\n",
    "    {\n",
    "        \"_index\": index_name, \n",
    "        \"_source\": {\n",
    "            \"fiqa_id\": sample['_id'],\n",
    "            \"fiqa_morfologik\": sample['text'],\n",
    "        }\n",
    "    }\n",
    "    for sample in ds_corpus['corpus']\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "727f7af0-2f51-4c20-a1e0-66b062028ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_index': 'fiqa_index',\n",
       " '_source': {'fiqa_id': '3',\n",
       "  'fiqa_morfologik': 'Nie mówię, że nie podoba mi się też pomysł szkolenia w miejscu pracy, ale nie możesz oczekiwać, że firma to zrobi. Szkolenie pracowników to nie ich praca – oni tworzą oprogramowanie. Być może systemy edukacyjne w Stanach Zjednoczonych (lub ich studenci) powinny trochę martwić się o zdobycie umiejętności rynkowych w zamian za ich ogromne inwestycje w edukację, zamiast wychodzić z tysiącami zadłużonych studentów i narzekać, że nie są do niczego wykwalifikowani.'}}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_to_add[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a9799f92-e851-43fd-a803-fd3adb761c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "5000 texts added succesfully.\n",
      "2638 texts added succesfully.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import helpers\n",
    "\n",
    "def batch_data(documents, batch_size=5000):\n",
    "    for i in range(0, len(documents), batch_size):\n",
    "        yield documents[i:i + batch_size]\n",
    "\n",
    "for batch in batch_data(documents_to_add, batch_size=5000):\n",
    "    success, failed = helpers.bulk(es, batch, raise_on_error=False,  ignore_status=[400, 404], timeout=\"120s\")\n",
    "    print(f\"{success} texts added succesfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e099a869-8264-4772-8028-0d392c82bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_dict = {q_id: [] for q_id in set(ds_qa[\"test\"]['query-id'])}\n",
    "simplified_query_test_only = {}\n",
    "\n",
    "for i in range(len(ds_qa[\"test\"])):\n",
    "    qa = ds_qa[\"test\"][i]\n",
    "    simplified_dict[qa[\"query-id\"]].append(qa[\"corpus-id\"])\n",
    "\n",
    "for i in range(len(ds_queries['queries'])):\n",
    "    if int(q_id := ds_queries['queries'][i]['_id']) in simplified_dict:\n",
    "        simplified_query_test_only[int(q_id)] = ds_queries['queries'][i]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "ec56377a-3ed0-4b8b-89b4-9fb01dddb74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def ndcg5(hits_ids, relevant_ids):\n",
    "    ideal_dcg = 0\n",
    "    dcg = 0\n",
    "    \n",
    "    for i in range(5):\n",
    "        if hits_ids[i] in relevant_ids:   \n",
    "            dcg += 1/np.log2(i+2)\n",
    "\n",
    "    for i in range(len(relevant_ids)):\n",
    "        ideal_dcg += 1/np.log2(i+2)\n",
    "\n",
    "    return dcg/ideal_dcg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "7a940ff3-1ec4-4b9d-b901-1949918a5f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_relevant_with_polbert(query, texts, separator, n=5):\n",
    "    texts_with_scores = []\n",
    "\n",
    "    model_texts = [query + separator + text for _, text in texts]\n",
    "    truncated_texts = []\n",
    "    \n",
    "    for text in model_texts:\n",
    "        tokens = tokenizer(text, truncation=True, max_length=256, return_tensors=\"pt\")\n",
    "        truncated_texts.append(tokenizer.decode(tokens[\"input_ids\"][0]))\n",
    "\n",
    "    results = classifier(truncated_texts)\n",
    "    \n",
    "    for i in range(len(results)):\n",
    "        if results[i]['label'] == \"LABEL_0\":\n",
    "            score = 1 - results[i]['score']\n",
    "        else: \n",
    "            score = results[i]['score']\n",
    "\n",
    "        texts_with_scores.append((texts[i][0], score))\n",
    "\n",
    "    sorted_scores = sorted(texts_with_scores, key=lambda x: x[1], reverse=True)\n",
    "    return sorted_scores[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "192c790d-7862-45c7-9c69-da7f85ce3670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ndcg(source):\n",
    "    ndcgs = []\n",
    "    N = 100\n",
    "    \n",
    "    for q_id in set(ds_qa[\"test\"]['query-id']):\n",
    "        query = simplified_query_test_only[q_id]\n",
    "        relevant_ids = simplified_dict[q_id]\n",
    "        \n",
    "        response = es.search(\n",
    "            index=index_name,\n",
    "            body={\n",
    "                \"query\": {\n",
    "                    \"match\": {\n",
    "                        source: query\n",
    "                    }\n",
    "                },\n",
    "                \"_source\": [\"fiqa_id\", \"fiqa_morfologik\"],\n",
    "                \"from\": 0,\n",
    "                \"size\": N  \n",
    "            }\n",
    "        )\n",
    "\n",
    "        hit_texts = [(int(hit['_source']['fiqa_id']), hit['_source']['fiqa_morfologik']) \n",
    "                     for hit in response['hits']['hits']]\n",
    "        \n",
    "        polbert_best = find_most_relevant_with_polbert(query, hit_texts, polbert_separator)\n",
    "        hit_ids = [scoring[0] for scoring in polbert_best]\n",
    "        ndcgs.append(ndcg5(hit_ids, relevant_ids))\n",
    "\n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ef389ffa-1957-44cf-b3e8-414f6a8a3c6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ndcg with polbert on 100 best ES matchings - 0.12113128082951996\n"
     ]
    }
   ],
   "source": [
    "mean_ndcg = calc_ndcg(\"fiqa_morfologik\")\n",
    "print(f\"ndcg with polbert on 100 best ES matchings - {mean_ndcg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "955397bc-216b-4d14-ae69-062b85562033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 'LABEL_1', 'score': 0.9972023963928223}\n",
      "{'label': 'LABEL_1', 'score': 0.9972135424613953}\n",
      "{'label': 'LABEL_1', 'score': 0.9970248341560364}\n",
      "{'label': 'LABEL_1', 'score': 0.9972267746925354}\n",
      "{'label': 'LABEL_1', 'score': 0.9964908957481384}\n",
      "{'label': 'LABEL_1', 'score': 0.9959766268730164}\n",
      "{'label': 'LABEL_1', 'score': 0.9964867830276489}\n",
      "{'label': 'LABEL_1', 'score': 0.9963847398757935}\n",
      "{'label': 'LABEL_1', 'score': 0.9965294003486633}\n",
      "{'label': 'LABEL_1', 'score': 0.9971676468849182}\n",
      "{'label': 'LABEL_1', 'score': 0.9969710111618042}\n",
      "{'label': 'LABEL_1', 'score': 0.9952327609062195}\n",
      "{'label': 'LABEL_1', 'score': 0.9960582256317139}\n",
      "{'label': 'LABEL_1', 'score': 0.996483325958252}\n",
      "{'label': 'LABEL_1', 'score': 0.9969987869262695}\n",
      "{'label': 'LABEL_1', 'score': 0.9970510005950928}\n",
      "{'label': 'LABEL_1', 'score': 0.9955151677131653}\n",
      "{'label': 'LABEL_1', 'score': 0.9968955516815186}\n",
      "{'label': 'LABEL_1', 'score': 0.9967095851898193}\n",
      "{'label': 'LABEL_1', 'score': 0.9972556233406067}\n",
      "{'label': 'LABEL_1', 'score': 0.9962228536605835}\n",
      "{'label': 'LABEL_1', 'score': 0.9968343377113342}\n",
      "{'label': 'LABEL_1', 'score': 0.9971877932548523}\n",
      "{'label': 'LABEL_1', 'score': 0.9798285365104675}\n",
      "{'label': 'LABEL_1', 'score': 0.9838843941688538}\n",
      "{'label': 'LABEL_1', 'score': 0.9973083734512329}\n",
      "{'label': 'LABEL_1', 'score': 0.9969966411590576}\n",
      "{'label': 'LABEL_1', 'score': 0.9957238435745239}\n",
      "{'label': 'LABEL_1', 'score': 0.9967676401138306}\n",
      "{'label': 'LABEL_1', 'score': 0.9968282580375671}\n",
      "{'label': 'LABEL_1', 'score': 0.9966086149215698}\n",
      "{'label': 'LABEL_1', 'score': 0.9967435002326965}\n",
      "{'label': 'LABEL_1', 'score': 0.9953304529190063}\n",
      "{'label': 'LABEL_1', 'score': 0.997628390789032}\n",
      "{'label': 'LABEL_1', 'score': 0.9964878559112549}\n",
      "{'label': 'LABEL_1', 'score': 0.9537904262542725}\n",
      "{'label': 'LABEL_1', 'score': 0.9956496357917786}\n",
      "{'label': 'LABEL_1', 'score': 0.9967940449714661}\n",
      "{'label': 'LABEL_1', 'score': 0.9938427209854126}\n",
      "{'label': 'LABEL_1', 'score': 0.9970473647117615}\n",
      "{'label': 'LABEL_1', 'score': 0.9959174990653992}\n",
      "{'label': 'LABEL_1', 'score': 0.9968247413635254}\n",
      "{'label': 'LABEL_1', 'score': 0.98941969871521}\n",
      "{'label': 'LABEL_1', 'score': 0.9925846457481384}\n",
      "{'label': 'LABEL_1', 'score': 0.9973467588424683}\n",
      "{'label': 'LABEL_1', 'score': 0.9925211071968079}\n",
      "{'label': 'LABEL_1', 'score': 0.9902948141098022}\n",
      "{'label': 'LABEL_1', 'score': 0.9971873164176941}\n",
      "{'label': 'LABEL_1', 'score': 0.9964339733123779}\n",
      "{'label': 'LABEL_1', 'score': 0.9963394403457642}\n",
      "{'label': 'LABEL_1', 'score': 0.9943153262138367}\n",
      "{'label': 'LABEL_1', 'score': 0.9953528642654419}\n",
      "{'label': 'LABEL_1', 'score': 0.9957852959632874}\n",
      "{'label': 'LABEL_1', 'score': 0.9960487484931946}\n",
      "{'label': 'LABEL_1', 'score': 0.996329128742218}\n",
      "{'label': 'LABEL_1', 'score': 0.9971416592597961}\n",
      "{'label': 'LABEL_1', 'score': 0.9106490015983582}\n",
      "{'label': 'LABEL_1', 'score': 0.9937660694122314}\n",
      "{'label': 'LABEL_1', 'score': 0.9964798092842102}\n",
      "{'label': 'LABEL_1', 'score': 0.9968039989471436}\n",
      "{'label': 'LABEL_1', 'score': 0.9975849390029907}\n",
      "{'label': 'LABEL_1', 'score': 0.9957257509231567}\n",
      "{'label': 'LABEL_1', 'score': 0.9958850741386414}\n",
      "{'label': 'LABEL_1', 'score': 0.9929948449134827}\n",
      "{'label': 'LABEL_1', 'score': 0.9969494938850403}\n",
      "{'label': 'LABEL_1', 'score': 0.9958458542823792}\n",
      "{'label': 'LABEL_1', 'score': 0.9948263764381409}\n",
      "{'label': 'LABEL_1', 'score': 0.9952573180198669}\n",
      "{'label': 'LABEL_1', 'score': 0.9963266253471375}\n",
      "{'label': 'LABEL_1', 'score': 0.9957185387611389}\n",
      "{'label': 'LABEL_1', 'score': 0.9967318773269653}\n",
      "{'label': 'LABEL_1', 'score': 0.9939852356910706}\n",
      "{'label': 'LABEL_1', 'score': 0.9949104189872742}\n",
      "{'label': 'LABEL_1', 'score': 0.9952284097671509}\n",
      "{'label': 'LABEL_1', 'score': 0.9960468411445618}\n",
      "{'label': 'LABEL_1', 'score': 0.9961001873016357}\n",
      "{'label': 'LABEL_1', 'score': 0.9966034889221191}\n",
      "{'label': 'LABEL_1', 'score': 0.9930185675621033}\n",
      "{'label': 'LABEL_1', 'score': 0.9952541589736938}\n",
      "{'label': 'LABEL_1', 'score': 0.993330180644989}\n",
      "{'label': 'LABEL_1', 'score': 0.9923503994941711}\n",
      "{'label': 'LABEL_1', 'score': 0.9966676831245422}\n",
      "{'label': 'LABEL_1', 'score': 0.8601567149162292}\n",
      "{'label': 'LABEL_1', 'score': 0.9957928657531738}\n",
      "{'label': 'LABEL_1', 'score': 0.9952953457832336}\n",
      "{'label': 'LABEL_1', 'score': 0.9938164353370667}\n",
      "{'label': 'LABEL_1', 'score': 0.9957271814346313}\n",
      "{'label': 'LABEL_1', 'score': 0.8002608418464661}\n",
      "{'label': 'LABEL_1', 'score': 0.9926077127456665}\n",
      "{'label': 'LABEL_1', 'score': 0.996206521987915}\n",
      "{'label': 'LABEL_1', 'score': 0.994385838508606}\n",
      "{'label': 'LABEL_1', 'score': 0.993865430355072}\n",
      "{'label': 'LABEL_1', 'score': 0.9944029450416565}\n",
      "{'label': 'LABEL_1', 'score': 0.9947896003723145}\n",
      "{'label': 'LABEL_1', 'score': 0.7227044701576233}\n",
      "{'label': 'LABEL_1', 'score': 0.9947360157966614}\n",
      "{'label': 'LABEL_1', 'score': 0.9543446898460388}\n",
      "{'label': 'LABEL_1', 'score': 0.9883596897125244}\n",
      "{'label': 'LABEL_1', 'score': 0.9967724680900574}\n",
      "{'label': 'LABEL_1', 'score': 0.994181215763092}\n"
     ]
    }
   ],
   "source": [
    "# results are worse than anything that was achieved with pure ES :(\n",
    "# best results achieved in ES exercise was ndcg = 0.182\n",
    "\n",
    "# modification of calc_ndcg to add some prints with polbert results and using olny first query \n",
    "# it turns out that almost all from top 100 sentences return by ES \n",
    "# are labeled as 'LABEL_1' with very high scores (over 0.99)\n",
    "\n",
    "mean_ndcg = calc_ndcg(\"fiqa_morfologik\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada9e0aa-d72c-4387-ad00-901afd829eeb",
   "metadata": {},
   "source": [
    "## Wnioski\n",
    "Niestety, po zastosowaniu w zadaniu dodatkowego modelu językowego do klasyfikacji, wyniki uzyskiwane w metryce ndcg@5, w porównaniu z wynikami uzyskiwanymi w labolatorium dotyczącym ES, uległy pogorszeniu. (Sam ES uzyskiwał ndcg@5 na poziomie 0.182, po zastosowaniu Polberta wynik w tej metryce to 0.121). \n",
    "Możliwe powody:\n",
    "- niskiej jakości zbiór danych i zbyt mała wybrana próbka\n",
    "- nieodpowiednie zbalansowanie danych w zbiorze treningowym - tylko dwukrotnie więcej próbek negatywnych w stosunku do pozytywnych, co nie oddawało proporcji w rzeczywistym zbiorze,  gdzie tylko kilka tekstów jest adekwatnych do pojedynczego zapytania\n",
    "\n",
    "## Odpowiedzi na pytania\n",
    "\n",
    "Prostsze metody, takie jak bag-of-words raczej nie byłyby użyteczne w tego typu zastosowaniach, ponieważ nie miałyby one szansy zobaczyć podziału na pytanie i odpowiedź, które są oddzielone specjalnym separatorem - w czasie zliczania słów w BOW uwzględniane byłyby zarówno elementy z pytania, jak i te z potencjalnej odpowiedzi.\n",
    "\n",
    "\n",
    "W zadaniu użyty został model [Polbert](https://huggingface.co/dkleczek/bert-base-polish-cased-v1), który bazuje na modelu bert-base-cased. Hiperparametry do treningu modelu zostały wybrane na podstawie [pliku README z repozytorium google](https://github.com/google-research/bert?tab=readme-ov-file#sentence-and-sentence-pair-classification-tasks). Z tego źródła zaczerpnięte zostały przede wszystkim watości learning_rate oraz num_train_epochs. Ilość epok została zwiększona w czasie przeprowadzania eksperymentu z 3, do 5, ale w użytych metrykach na zbiorze walidacyjnym nie przyniosło poprawy wyników. Z [tego samego źródła](https://github.com/google-research/bert?tab=readme-ov-file#out-of-memory-issues) pozyskane zostały też informacje, jak powinna być dobrana maksymalna długość sekwencji oraz batch_size dla kart graficznych, na których odbywał się trening modelu.\n",
    "\n",
    "\n",
    "Zalety sieci neuronowych w NLP:\n",
    "- pozwalają wykryć znacznie bardziej skomplikowane powiązania pomiędzy słowami w tekstach, niż jakiekolwiek inne modele\n",
    "- dzięki bibliotekom takim jak transformers mogą być łatwo dostosowywane do różnych zadań (dodawanie nowych tokenów na końcu zdań, klasyfikacja, uzupełnianie luk w tekście)\n",
    "\n",
    "Wady sieci neuronowych w NLP:\n",
    "- aby były efektywne, wymagają olbrzymich ilości wysokiej jakości danych, które ciężko jest pozyskać i zweryfikować\n",
    "- trening takich modeli oraz ich używanie wymaga dużych mocy obliczeniowych, które są drogie w zakupie i zużywają ogromne ilości energii\n",
    "- kontrola nad procesem uczenia i możliwość pełnego przetestowania modelu jest dość ograniczona, dlatego model może w niektórych sytuacjach zwracać niespodziewane wyniki (np. zapamiętywać wiadomości, które są prawdziwe tylko w określonych warunkach)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b546fd6e-d8c3-485e-8977-f8a5ee319bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
